{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Librariesfrom keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import re\n",
    "import warnings\n",
    "from keras.models import load_model\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from keras import initializers\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.utils import CustomObjectScope\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        #print(filename)\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "images1=load_images_from_folder(\"preprocessed3/daisy\")\n",
    "images2=load_images_from_folder(\"preprocessed3/dandelion\")\n",
    "images3=load_images_from_folder(\"preprocessed3/rose\")\n",
    "images4=load_images_from_folder(\"preprocessed3/sunflower\")\n",
    "images5=load_images_from_folder(\"preprocessed3/tulip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "images1=np.asarray(images1)\n",
    "images2=np.asarray(images2)\n",
    "images3=np.asarray(images3)\n",
    "images4=np.asarray(images4)\n",
    "images5=np.asarray(images5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(150, 150, 3)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images1[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.concatenate((images1,images2,images3,images4,images5),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(images5)):\n",
    "#     images5[i]=cv2.resize(images5[i], (150, 150)) \n",
    "#     #gray = cv2.cvtColor(images5[i], cv2.COLOR_BGR2GRAY)\n",
    "#     cv2.imwrite(f\"preprocessed3/tulip/{i}.jpg\", images5[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[0.51372549, 0.53333333, 0.52941176],\n",
       "         [0.55294118, 0.57254902, 0.56862745],\n",
       "         [0.56862745, 0.56862745, 0.56862745],\n",
       "         ...,\n",
       "         [0.6       , 0.60392157, 0.59607843],\n",
       "         [0.6       , 0.6       , 0.6       ],\n",
       "         [0.59607843, 0.59607843, 0.59607843]],\n",
       "\n",
       "        [[0.50980392, 0.52941176, 0.5254902 ],\n",
       "         [0.54901961, 0.56862745, 0.56470588],\n",
       "         [0.55686275, 0.56470588, 0.56470588],\n",
       "         ...,\n",
       "         [0.6       , 0.60392157, 0.59607843],\n",
       "         [0.60392157, 0.60392157, 0.60392157],\n",
       "         [0.58431373, 0.58431373, 0.58431373]],\n",
       "\n",
       "        [[0.50588235, 0.52941176, 0.5254902 ],\n",
       "         [0.54901961, 0.56862745, 0.56470588],\n",
       "         [0.55686275, 0.56470588, 0.56470588],\n",
       "         ...,\n",
       "         [0.60392157, 0.60392157, 0.60392157],\n",
       "         [0.59215686, 0.59215686, 0.59215686],\n",
       "         [0.57647059, 0.57647059, 0.57647059]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.09803922, 0.18823529, 0.17254902],\n",
       "         [0.09803922, 0.18823529, 0.17254902],\n",
       "         [0.09803922, 0.18823529, 0.17254902],\n",
       "         ...,\n",
       "         [0.47843137, 0.49019608, 0.50588235],\n",
       "         [0.47843137, 0.49019608, 0.50588235],\n",
       "         [0.48235294, 0.49411765, 0.50980392]],\n",
       "\n",
       "        [[0.09803922, 0.18823529, 0.17254902],\n",
       "         [0.10196078, 0.19215686, 0.17647059],\n",
       "         [0.10980392, 0.19215686, 0.18039216],\n",
       "         ...,\n",
       "         [0.49411765, 0.49803922, 0.51372549],\n",
       "         [0.49019608, 0.49411765, 0.50980392],\n",
       "         [0.49019608, 0.49411765, 0.50980392]],\n",
       "\n",
       "        [[0.09411765, 0.18431373, 0.16862745],\n",
       "         [0.09803922, 0.18823529, 0.17254902],\n",
       "         [0.10980392, 0.19215686, 0.18039216],\n",
       "         ...,\n",
       "         [0.49803922, 0.50196078, 0.51764706],\n",
       "         [0.49411765, 0.49803922, 0.51372549],\n",
       "         [0.49411765, 0.49803922, 0.51372549]]],\n",
       "\n",
       "\n",
       "       [[[0.8745098 , 0.85490196, 0.84313725],\n",
       "         [0.85882353, 0.83921569, 0.82745098],\n",
       "         [0.8745098 , 0.84705882, 0.83529412],\n",
       "         ...,\n",
       "         [0.05882353, 0.05098039, 0.04705882],\n",
       "         [0.04705882, 0.03921569, 0.03529412],\n",
       "         [0.04313725, 0.03529412, 0.03137255]],\n",
       "\n",
       "        [[0.8627451 , 0.84313725, 0.83137255],\n",
       "         [0.89019608, 0.87058824, 0.85882353],\n",
       "         [0.87843137, 0.85098039, 0.83921569],\n",
       "         ...,\n",
       "         [0.0627451 , 0.05490196, 0.05098039],\n",
       "         [0.03921569, 0.03137255, 0.02745098],\n",
       "         [0.03137255, 0.02352941, 0.01960784]],\n",
       "\n",
       "        [[0.9254902 , 0.90588235, 0.89411765],\n",
       "         [0.90588235, 0.88627451, 0.8745098 ],\n",
       "         [0.89803922, 0.87058824, 0.85882353],\n",
       "         ...,\n",
       "         [0.0627451 , 0.05490196, 0.05098039],\n",
       "         [0.03921569, 0.03137255, 0.02745098],\n",
       "         [0.02745098, 0.01960784, 0.01568627]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.71372549, 0.69803922, 0.69411765],\n",
       "         [0.73333333, 0.71764706, 0.71372549],\n",
       "         [0.80392157, 0.78431373, 0.78039216],\n",
       "         ...,\n",
       "         [0.55294118, 0.59607843, 0.62745098],\n",
       "         [0.61960784, 0.65490196, 0.69019608],\n",
       "         [0.63921569, 0.6745098 , 0.70980392]],\n",
       "\n",
       "        [[0.85882353, 0.83921569, 0.82745098],\n",
       "         [0.88235294, 0.8627451 , 0.85098039],\n",
       "         [0.90196078, 0.88235294, 0.87058824],\n",
       "         ...,\n",
       "         [0.54901961, 0.6       , 0.63137255],\n",
       "         [0.63137255, 0.6745098 , 0.70588235],\n",
       "         [0.62745098, 0.67058824, 0.70196078]],\n",
       "\n",
       "        [[0.9372549 , 0.91764706, 0.90588235],\n",
       "         [0.91372549, 0.89411765, 0.88235294],\n",
       "         [0.94117647, 0.92156863, 0.90980392],\n",
       "         ...,\n",
       "         [0.54509804, 0.59607843, 0.62745098],\n",
       "         [0.63137255, 0.6745098 , 0.70588235],\n",
       "         [0.61176471, 0.65490196, 0.68627451]]],\n",
       "\n",
       "\n",
       "       [[[0.09411765, 0.09411765, 0.09411765],\n",
       "         [0.10196078, 0.10196078, 0.10196078],\n",
       "         [0.10588235, 0.10588235, 0.10588235],\n",
       "         ...,\n",
       "         [0.12156863, 0.12156863, 0.12156863],\n",
       "         [0.12156863, 0.12156863, 0.12156863],\n",
       "         [0.12156863, 0.12156863, 0.12156863]],\n",
       "\n",
       "        [[0.09803922, 0.09803922, 0.09803922],\n",
       "         [0.10588235, 0.10588235, 0.10588235],\n",
       "         [0.10980392, 0.10980392, 0.10980392],\n",
       "         ...,\n",
       "         [0.12941176, 0.12941176, 0.12941176],\n",
       "         [0.1254902 , 0.1254902 , 0.1254902 ],\n",
       "         [0.1254902 , 0.1254902 , 0.1254902 ]],\n",
       "\n",
       "        [[0.09803922, 0.09803922, 0.09803922],\n",
       "         [0.10980392, 0.10980392, 0.10980392],\n",
       "         [0.11372549, 0.11372549, 0.11372549],\n",
       "         ...,\n",
       "         [0.12941176, 0.12941176, 0.12941176],\n",
       "         [0.1254902 , 0.1254902 , 0.1254902 ],\n",
       "         [0.1254902 , 0.1254902 , 0.1254902 ]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.05882353, 0.05882353, 0.05882353],\n",
       "         [0.0627451 , 0.0627451 , 0.0627451 ],\n",
       "         [0.06666667, 0.06666667, 0.06666667],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.05882353, 0.05882353, 0.05882353],\n",
       "         [0.0627451 , 0.0627451 , 0.0627451 ],\n",
       "         [0.06666667, 0.06666667, 0.06666667],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]],\n",
       "\n",
       "        [[0.0627451 , 0.0627451 , 0.0627451 ],\n",
       "         [0.0627451 , 0.0627451 , 0.0627451 ],\n",
       "         [0.06666667, 0.06666667, 0.06666667],\n",
       "         ...,\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ],\n",
       "         [0.        , 0.        , 0.        ]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[0.59215686, 0.60392157, 0.62352941],\n",
       "         [0.56862745, 0.58431373, 0.60392157],\n",
       "         [0.27843137, 0.29803922, 0.30980392],\n",
       "         ...,\n",
       "         [0.60392157, 0.65882353, 0.65490196],\n",
       "         [0.79215686, 0.83529412, 0.82745098],\n",
       "         [0.77647059, 0.81960784, 0.80784314]],\n",
       "\n",
       "        [[0.70980392, 0.75686275, 0.78039216],\n",
       "         [0.57254902, 0.61568627, 0.63137255],\n",
       "         [0.6745098 , 0.70196078, 0.71372549],\n",
       "         ...,\n",
       "         [0.76078431, 0.82745098, 0.81568627],\n",
       "         [0.6745098 , 0.72941176, 0.71372549],\n",
       "         [0.67843137, 0.73333333, 0.70980392]],\n",
       "\n",
       "        [[0.70196078, 0.81568627, 0.85098039],\n",
       "         [0.76470588, 0.85882353, 0.88235294],\n",
       "         [0.83137255, 0.87843137, 0.87843137],\n",
       "         ...,\n",
       "         [0.67058824, 0.75686275, 0.7372549 ],\n",
       "         [0.65490196, 0.7254902 , 0.69803922],\n",
       "         [0.61960784, 0.69411765, 0.65882353]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.00392157, 0.00784314, 0.        ],\n",
       "         [0.17647059, 0.18039216, 0.14509804],\n",
       "         [0.28627451, 0.29411765, 0.21960784],\n",
       "         ...,\n",
       "         [0.04705882, 0.10980392, 0.06666667],\n",
       "         [0.04313725, 0.13333333, 0.11764706],\n",
       "         [0.        , 0.0627451 , 0.0627451 ]],\n",
       "\n",
       "        [[0.03137255, 0.04313725, 0.00784314],\n",
       "         [0.20392157, 0.21176471, 0.16470588],\n",
       "         [0.28235294, 0.29019608, 0.21568627],\n",
       "         ...,\n",
       "         [0.04313725, 0.1254902 , 0.09019608],\n",
       "         [0.07058824, 0.19607843, 0.19215686],\n",
       "         [0.07058824, 0.21960784, 0.22745098]],\n",
       "\n",
       "        [[0.05882353, 0.0745098 , 0.03137255],\n",
       "         [0.18039216, 0.18823529, 0.14117647],\n",
       "         [0.15686275, 0.16470588, 0.09019608],\n",
       "         ...,\n",
       "         [0.03529412, 0.12941176, 0.09019608],\n",
       "         [0.05490196, 0.19607843, 0.19607843],\n",
       "         [0.12941176, 0.29803922, 0.30980392]]],\n",
       "\n",
       "\n",
       "       [[[0.23529412, 0.23137255, 0.23921569],\n",
       "         [0.24313725, 0.25490196, 0.24705882],\n",
       "         [0.14117647, 0.18039216, 0.13333333],\n",
       "         ...,\n",
       "         [0.67058824, 0.62352941, 0.6       ],\n",
       "         [0.31372549, 0.26666667, 0.24313725],\n",
       "         [0.36078431, 0.31764706, 0.28627451]],\n",
       "\n",
       "        [[0.15686275, 0.17254902, 0.17647059],\n",
       "         [0.17254902, 0.19215686, 0.18431373],\n",
       "         [0.23137255, 0.2627451 , 0.21960784],\n",
       "         ...,\n",
       "         [0.5254902 , 0.47843137, 0.45490196],\n",
       "         [0.62352941, 0.58039216, 0.54901961],\n",
       "         [0.61960784, 0.57647059, 0.54509804]],\n",
       "\n",
       "        [[0.09803922, 0.14901961, 0.15686275],\n",
       "         [0.0745098 , 0.11764706, 0.10980392],\n",
       "         [0.22352941, 0.24313725, 0.20784314],\n",
       "         ...,\n",
       "         [0.69411765, 0.65490196, 0.61568627],\n",
       "         [0.44313725, 0.4       , 0.36862745],\n",
       "         [0.39215686, 0.34509804, 0.32156863]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.03529412, 0.29019608, 0.46666667],\n",
       "         [0.07843137, 0.29803922, 0.45882353],\n",
       "         [0.0627451 , 0.21960784, 0.33333333],\n",
       "         ...,\n",
       "         [0.        , 0.22745098, 0.17254902],\n",
       "         [0.0627451 , 0.29411765, 0.23921569],\n",
       "         [0.04313725, 0.2745098 , 0.21960784]],\n",
       "\n",
       "        [[0.02352941, 0.23921569, 0.36078431],\n",
       "         [0.        , 0.18431373, 0.28627451],\n",
       "         [0.        , 0.03921569, 0.10588235],\n",
       "         ...,\n",
       "         [0.        , 0.2       , 0.14901961],\n",
       "         [0.02352941, 0.25490196, 0.2       ],\n",
       "         [0.        , 0.21960784, 0.16078431]],\n",
       "\n",
       "        [[0.        , 0.10980392, 0.2       ],\n",
       "         [0.        , 0.12941176, 0.2       ],\n",
       "         [0.03529412, 0.2       , 0.24705882],\n",
       "         ...,\n",
       "         [0.03921569, 0.25882353, 0.20784314],\n",
       "         [0.        , 0.22745098, 0.16862745],\n",
       "         [0.09803922, 0.32941176, 0.27058824]]],\n",
       "\n",
       "\n",
       "       [[[0.19607843, 0.4       , 0.33333333],\n",
       "         [0.16470588, 0.38039216, 0.31372549],\n",
       "         [0.13333333, 0.39607843, 0.31372549],\n",
       "         ...,\n",
       "         [0.23137255, 0.05882353, 0.21960784],\n",
       "         [0.24313725, 0.06666667, 0.23529412],\n",
       "         [0.27058824, 0.09411765, 0.2627451 ]],\n",
       "\n",
       "        [[0.19607843, 0.4       , 0.33333333],\n",
       "         [0.16470588, 0.38039216, 0.31372549],\n",
       "         [0.14117647, 0.39607843, 0.31372549],\n",
       "         ...,\n",
       "         [0.23529412, 0.0627451 , 0.22352941],\n",
       "         [0.24705882, 0.07058824, 0.23921569],\n",
       "         [0.27058824, 0.09411765, 0.2627451 ]],\n",
       "\n",
       "        [[0.18431373, 0.39607843, 0.32941176],\n",
       "         [0.15686275, 0.38431373, 0.31372549],\n",
       "         [0.14509804, 0.39215686, 0.31372549],\n",
       "         ...,\n",
       "         [0.23921569, 0.06666667, 0.22745098],\n",
       "         [0.25098039, 0.0745098 , 0.24313725],\n",
       "         [0.2745098 , 0.09803922, 0.26666667]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.17254902, 0.05490196, 0.15294118],\n",
       "         [0.17254902, 0.05882353, 0.15686275],\n",
       "         [0.18823529, 0.06666667, 0.17254902],\n",
       "         ...,\n",
       "         [0.07058824, 0.10196078, 0.0745098 ],\n",
       "         [0.08627451, 0.09019608, 0.08235294],\n",
       "         [0.08627451, 0.06666667, 0.07058824]],\n",
       "\n",
       "        [[0.17254902, 0.0627451 , 0.15294118],\n",
       "         [0.16078431, 0.05882353, 0.14901961],\n",
       "         [0.17647059, 0.06666667, 0.15686275],\n",
       "         ...,\n",
       "         [0.0627451 , 0.10588235, 0.0745098 ],\n",
       "         [0.09019608, 0.09411765, 0.08627451],\n",
       "         [0.08235294, 0.0745098 , 0.0745098 ]],\n",
       "\n",
       "        [[0.17254902, 0.0745098 , 0.15294118],\n",
       "         [0.16078431, 0.0627451 , 0.14117647],\n",
       "         [0.16470588, 0.0627451 , 0.15294118],\n",
       "         ...,\n",
       "         [0.07058824, 0.11372549, 0.08235294],\n",
       "         [0.08235294, 0.09411765, 0.08627451],\n",
       "         [0.08627451, 0.07843137, 0.07843137]]]])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.zeros(len(images))\n",
    "y[len(images1):]=1\n",
    "y[len(images1)+len(images2):]=2\n",
    "y[len(images1)+len(images2)+len(images3):]=3\n",
    "y[len(images1)+len(images2)+len(images3)+len(images4):]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2782]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "y= np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.expand_dims(images, axis=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4323, 150, 150, 1, 3)"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(images, y, test_size=0.2, random_state=0)#train test random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3458, 150, 150, 1, 3)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Input 0 of layer conv2d_8 is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: [None, 150, 150, 1, 3]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-61-8f5e9602ffc0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mSequential\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mConv2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m16\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m5\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mactivation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'relu'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0minput_shape\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mDropout\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mMaxPooling2D\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpool_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tcs\\lib\\site-packages\\tensorflow\\python\\training\\checkpointable\\base.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    440\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    441\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 442\u001b[1;33m       \u001b[0mmethod\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    443\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    444\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_setattr_tracking\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mprevious_value\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tcs\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py\u001b[0m in \u001b[0;36madd\u001b[1;34m(self, layer)\u001b[0m\n\u001b[0;32m    162\u001b[0m           \u001b[1;31m# and create the node connecting the current layer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    163\u001b[0m           \u001b[1;31m# to the input layer we just created.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 164\u001b[1;33m           \u001b[0mlayer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    165\u001b[0m           \u001b[0mset_inputs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    166\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tcs\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[0;32m    536\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuilt\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    537\u001b[0m         \u001b[1;31m# Build layer if applicable (if the `build` method has been overridden).\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 538\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_build\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    539\u001b[0m         \u001b[1;31m# We must set self.built since user defined build functions are not\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;31m# constrained to set self.built.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tcs\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\base_layer.py\u001b[0m in \u001b[0;36m_maybe_build\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   1589\u001b[0m     \u001b[1;31m# Check input assumptions set before layer building, e.g. input rank.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1590\u001b[0m     input_spec.assert_input_compatibility(\n\u001b[1;32m-> 1591\u001b[1;33m         self.input_spec, inputs, self.name)\n\u001b[0m\u001b[0;32m   1592\u001b[0m     \u001b[0minput_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1593\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minput_list\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dtype\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tcs\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\input_spec.py\u001b[0m in \u001b[0;36massert_input_compatibility\u001b[1;34m(input_spec, inputs, layer_name)\u001b[0m\n\u001b[0;32m    121\u001b[0m                          \u001b[1;34m'expected ndim='\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m', found ndim='\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    122\u001b[0m                          \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m'. Full shape received: '\u001b[0m \u001b[1;33m+\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m                          str(x.shape.as_list()))\n\u001b[0m\u001b[0;32m    124\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mspec\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_ndim\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m       \u001b[0mndim\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndims\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Input 0 of layer conv2d_8 is incompatible with the layer: expected ndim=4, found ndim=5. Full shape received: [None, 150, 150, 1, 3]"
     ]
    }
   ],
   "source": [
    "#filepath = \"CNN-{epoch:02d}-{val_acc:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
    "#checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) # saves only the best ones\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(16,(5,5), activation='relu',input_shape=(X_train[0].shape)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(32,(4,4),activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64,(3,3),activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(96,(3,3),activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "for layer in model.layers:\n",
    "    \n",
    "    print(layer.output_shape)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2766 samples, validate on 692 samples\n",
      "Epoch 1/10\n",
      "2766/2766 [==============================] - 103s 37ms/sample - loss: 1.5852 - acc: 0.2719 - val_loss: 1.5363 - val_acc: 0.3584\n",
      "Epoch 2/10\n",
      "2766/2766 [==============================] - 101s 37ms/sample - loss: 1.4844 - acc: 0.3547 - val_loss: 1.5495 - val_acc: 0.3223\n",
      "Epoch 3/10\n",
      "2766/2766 [==============================] - 103s 37ms/sample - loss: 1.4138 - acc: 0.4103 - val_loss: 1.4684 - val_acc: 0.3974\n",
      "Epoch 4/10\n",
      "2766/2766 [==============================] - 105s 38ms/sample - loss: 1.3005 - acc: 0.4704 - val_loss: 1.4795 - val_acc: 0.3367\n",
      "Epoch 5/10\n",
      "2766/2766 [==============================] - 101s 37ms/sample - loss: 1.2271 - acc: 0.5098 - val_loss: 1.3779 - val_acc: 0.4176\n",
      "Epoch 6/10\n",
      "2766/2766 [==============================] - 102s 37ms/sample - loss: 1.1272 - acc: 0.5568 - val_loss: 1.3617 - val_acc: 0.4523\n",
      "Epoch 7/10\n",
      "2766/2766 [==============================] - 101s 36ms/sample - loss: 1.0536 - acc: 0.5868 - val_loss: 1.3357 - val_acc: 0.4335\n",
      "Epoch 8/10\n",
      "2766/2766 [==============================] - 102s 37ms/sample - loss: 0.9640 - acc: 0.6309 - val_loss: 1.3196 - val_acc: 0.4754\n",
      "Epoch 9/10\n",
      "2766/2766 [==============================] - 102s 37ms/sample - loss: 0.8829 - acc: 0.6569 - val_loss: 1.3081 - val_acc: 0.4783\n",
      "Epoch 10/10\n",
      "2766/2766 [==============================] - 101s 36ms/sample - loss: 0.7492 - acc: 0.7180 - val_loss: 1.3014 - val_acc: 0.4913\n"
     ]
    }
   ],
   "source": [
    "history1=model.fit(X_train,Y_train, batch_size=32, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history2=model.fit(X_train,Y_train, batch_size=32, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history3=model.fit(X_train,Y_train, batch_size=32, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.500578034682081\n",
      "[[ 38  55  24  22  23]\n",
      " [  2 136  17  33  18]\n",
      " [  2  23  65  29  33]\n",
      " [  1  14  21  86  25]\n",
      " [  2  18  34  36 108]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.23      0.37       162\n",
      "           1       0.55      0.66      0.60       206\n",
      "           2       0.40      0.43      0.42       152\n",
      "           3       0.42      0.59      0.49       147\n",
      "           4       0.52      0.55      0.53       198\n",
      "\n",
      "    accuracy                           0.50       865\n",
      "   macro avg       0.55      0.49      0.48       865\n",
      "weighted avg       0.55      0.50      0.49       865\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "Y_test2=np.argmax(Y_test,axis=1)\n",
    "Y_pred=model.predict(X_test)\n",
    "#print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "acc=accuracy_score(Y_test2, y_pred)\n",
    "print(acc)\n",
    "print(confusion_matrix(Y_test2,y_pred))\n",
    "print(classification_report(Y_test2,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x234f51634a8>]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history1.history['acc'])\n",
    "plt.plot(history1.history['val_acc'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history_gray.history_gray['acc'])\n",
    "plt.plot(history_gray.history_gray['val_acc'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
