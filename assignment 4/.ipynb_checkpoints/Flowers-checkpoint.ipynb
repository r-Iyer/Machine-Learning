{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Import Librariesfrom keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import re\n",
    "import warnings\n",
    "from keras.models import load_model\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.preprocessing import label_binarize\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "import seaborn as sns\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.decomposition import PCA\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_selection import SelectKBest,chi2\n",
    "from sklearn.metrics import roc_curve,auc\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "from keras import initializers\n",
    "import keras\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from keras.utils import CustomObjectScope\n",
    "from keras.initializers import glorot_uniform\n",
    "from keras.models import load_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_images_from_folder(folder):\n",
    "    images = []\n",
    "    for filename in os.listdir(folder):\n",
    "        #print(filename)\n",
    "        img = cv2.imread(os.path.join(folder,filename))\n",
    "        if img is not None:\n",
    "            images.append(img)\n",
    "    return images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images1=load_images_from_folder(\"flowers/daisy\")\n",
    "images2=load_images_from_folder(\"flowers/dandelion\")\n",
    "images3=load_images_from_folder(\"flowers/rose\")\n",
    "images4=load_images_from_folder(\"flowers/sunflower\")\n",
    "images5=load_images_from_folder(\"flowers/tulip\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images1=np.asarray(images1)\n",
    "images2=np.asarray(images2)\n",
    "images3=np.asarray(images3)\n",
    "images4=np.asarray(images4)\n",
    "images5=np.asarray(images5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images1[5].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.concatenate((images1,images2,images3,images4,images5),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=images/255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for i in range(len(images5)):\n",
    "#     images5[i]=cv2.resize(images5[i], (150, 150)) \n",
    "#     gray = cv2.cvtColor(images5[i], cv2.COLOR_BGR2GRAY)\n",
    "#     cv2.imwrite(f\"preprocessed2/tulip/{i}.jpg\", gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0.52941176, 0.56862745, 0.56862745, ..., 0.6       ,\n",
       "         0.6       , 0.59607843],\n",
       "        [0.5254902 , 0.56470588, 0.56470588, ..., 0.6       ,\n",
       "         0.60392157, 0.58431373],\n",
       "        [0.5254902 , 0.56470588, 0.56470588, ..., 0.60392157,\n",
       "         0.59215686, 0.57647059],\n",
       "        ...,\n",
       "        [0.17254902, 0.17254902, 0.17254902, ..., 0.49411765,\n",
       "         0.49411765, 0.49803922],\n",
       "        [0.17254902, 0.17647059, 0.18039216, ..., 0.50196078,\n",
       "         0.49803922, 0.49803922],\n",
       "        [0.16862745, 0.17254902, 0.18039216, ..., 0.50588235,\n",
       "         0.50196078, 0.50196078]],\n",
       "\n",
       "       [[0.85490196, 0.83921569, 0.84705882, ..., 0.05098039,\n",
       "         0.03921569, 0.03529412],\n",
       "        [0.84313725, 0.87058824, 0.85098039, ..., 0.05490196,\n",
       "         0.03137255, 0.02352941],\n",
       "        [0.90588235, 0.88627451, 0.87058824, ..., 0.05490196,\n",
       "         0.03137255, 0.01960784],\n",
       "        ...,\n",
       "        [0.69803922, 0.71764706, 0.78431373, ..., 0.6       ,\n",
       "         0.6627451 , 0.68235294],\n",
       "        [0.83921569, 0.8627451 , 0.88235294, ..., 0.60392157,\n",
       "         0.67843137, 0.6745098 ],\n",
       "        [0.91764706, 0.89411765, 0.92156863, ..., 0.6       ,\n",
       "         0.67843137, 0.65882353]],\n",
       "\n",
       "       [[0.09411765, 0.10196078, 0.10588235, ..., 0.12156863,\n",
       "         0.12156863, 0.12156863],\n",
       "        [0.09803922, 0.10588235, 0.10980392, ..., 0.12941176,\n",
       "         0.1254902 , 0.1254902 ],\n",
       "        [0.09803922, 0.10980392, 0.11372549, ..., 0.12941176,\n",
       "         0.1254902 , 0.1254902 ],\n",
       "        ...,\n",
       "        [0.05882353, 0.0627451 , 0.06666667, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.05882353, 0.0627451 , 0.06666667, ..., 0.        ,\n",
       "         0.        , 0.        ],\n",
       "        [0.0627451 , 0.0627451 , 0.06666667, ..., 0.        ,\n",
       "         0.        , 0.        ]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[0.60784314, 0.58823529, 0.29803922, ..., 0.65098039,\n",
       "         0.82745098, 0.81176471],\n",
       "        [0.75686275, 0.61568627, 0.70196078, ..., 0.81568627,\n",
       "         0.71764706, 0.72156863],\n",
       "        [0.81176471, 0.85490196, 0.8745098 , ..., 0.74117647,\n",
       "         0.70980392, 0.6745098 ],\n",
       "        ...,\n",
       "        [0.00392157, 0.16862745, 0.27058824, ..., 0.09019608,\n",
       "         0.11764706, 0.05098039],\n",
       "        [0.03137255, 0.19607843, 0.26666667, ..., 0.10588235,\n",
       "         0.18039216, 0.20392157],\n",
       "        [0.05882353, 0.17254902, 0.14117647, ..., 0.10588235,\n",
       "         0.18039216, 0.28235294]],\n",
       "\n",
       "       [[0.23529412, 0.25098039, 0.16078431, ..., 0.62352941,\n",
       "         0.26666667, 0.31372549],\n",
       "        [0.17254902, 0.18823529, 0.24705882, ..., 0.47843137,\n",
       "         0.57647059, 0.57254902],\n",
       "        [0.14509804, 0.10980392, 0.23137255, ..., 0.64705882,\n",
       "         0.39607843, 0.34509804],\n",
       "        ...,\n",
       "        [0.31372549, 0.32156863, 0.23529412, ..., 0.18431373,\n",
       "         0.25098039, 0.23137255],\n",
       "        [0.25098039, 0.19215686, 0.03921569, ..., 0.16078431,\n",
       "         0.21176471, 0.17647059],\n",
       "        [0.11372549, 0.12941176, 0.19607843, ..., 0.21960784,\n",
       "         0.18431373, 0.28627451]],\n",
       "\n",
       "       [[0.35686275, 0.3372549 , 0.34117647, ..., 0.1254902 ,\n",
       "         0.1372549 , 0.16470588],\n",
       "        [0.35686275, 0.3372549 , 0.34117647, ..., 0.12941176,\n",
       "         0.14117647, 0.16470588],\n",
       "        [0.35294118, 0.3372549 , 0.34117647, ..., 0.13333333,\n",
       "         0.14509804, 0.16862745],\n",
       "        ...,\n",
       "        [0.09803922, 0.10196078, 0.11372549, ..., 0.09019608,\n",
       "         0.08627451, 0.07058824],\n",
       "        [0.10196078, 0.09803922, 0.10588235, ..., 0.09019608,\n",
       "         0.09019608, 0.0745098 ],\n",
       "        [0.10980392, 0.09803922, 0.10196078, ..., 0.09803922,\n",
       "         0.09019608, 0.07843137]]])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y=np.zeros(len(images))\n",
    "y[len(images1):]=1\n",
    "y[len(images1)+len(images2):]=2\n",
    "y[len(images1)+len(images2)+len(images3):]=3\n",
    "y[len(images1)+len(images2)+len(images3)+len(images4):]=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[2782]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from keras.utils import np_utils\n",
    "encoder = LabelEncoder()\n",
    "encoder.fit(y)\n",
    "y = encoder.transform(y)\n",
    "y= np_utils.to_categorical(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "images=np.expand_dims(images, axis=3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4323, 150, 150, 1)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(images, y, test_size=0.2, random_state=0)#train test random split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3458, 150, 150, 1)"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(None, 148, 148, 32)\n",
      "(None, 148, 148, 32)\n",
      "(None, 74, 74, 32)\n",
      "(None, 72, 72, 64)\n",
      "(None, 72, 72, 64)\n",
      "(None, 36, 36, 64)\n",
      "(None, 34, 34, 128)\n",
      "(None, 34, 34, 128)\n",
      "(None, 17, 17, 128)\n",
      "(None, 15, 15, 128)\n",
      "(None, 15, 15, 128)\n",
      "(None, 7, 7, 128)\n",
      "(None, 6272)\n",
      "(None, 64)\n",
      "(None, 5)\n",
      "(None, 5)\n"
     ]
    }
   ],
   "source": [
    "#filepath = \"CNN-{epoch:02d}-{val_acc:.3f}\"  # unique file name that will include the epoch and the validation acc for that epoch\n",
    "#checkpoint = ModelCheckpoint(\"models/{}.model\".format(filepath, monitor='val_acc', verbose=1, save_best_only=True, mode='max')) # saves only the best ones\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D,BatchNormalization\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Conv2D(32, (3,3), activation='relu',input_shape=(X_train[0].shape)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(64, (3,3),activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3,3),activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "#model.add(BatchNormalization())\n",
    "\n",
    "model.add(Conv2D(128, (3,3),activation='relu'))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "\n",
    "model.add(Flatten())  # this converts our 3D feature maps to 1D feature vectors\n",
    "\n",
    "model.add(Dense(64))\n",
    "\n",
    "model.add(Dense(5))\n",
    "model.add(Activation('softmax'))\n",
    "for layer in model.layers:\n",
    "    \n",
    "    print(layer.output_shape)\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='adam',\n",
    "              metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 2766 samples, validate on 692 samples\n",
      "Epoch 1/10\n",
      "2766/2766 [==============================] - 152s 55ms/sample - loss: 1.6290 - acc: 0.2722 - val_loss: 1.5904 - val_acc: 0.3121\n",
      "Epoch 2/10\n",
      "1280/2766 [============>.................] - ETA: 56s - loss: 1.5346 - acc: 0.3148 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-69-c00b575054da>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m128\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m10\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0.2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\.conda\\envs\\tcs\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    878\u001b[0m           \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    879\u001b[0m           \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 880\u001b[1;33m           validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    882\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\.conda\\envs\\tcs\\lib\\site-packages\\tensorflow\\python\\keras\\engine\\training_arrays.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, inputs, targets, sample_weights, batch_size, epochs, verbose, callbacks, val_inputs, val_targets, val_sample_weights, shuffle, initial_epoch, steps_per_epoch, validation_steps, mode, validation_in_fit, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    328\u001b[0m         \u001b[1;31m# Get outputs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 329\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    330\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    331\u001b[0m           \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\.conda\\envs\\tcs\\lib\\site-packages\\tensorflow\\python\\keras\\backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   3074\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3075\u001b[0m     fetched = self._callable_fn(*array_vals,\n\u001b[1;32m-> 3076\u001b[1;33m                                 run_metadata=self.run_metadata)\n\u001b[0m\u001b[0;32m   3077\u001b[0m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_fetch_callbacks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfetched\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   3078\u001b[0m     return nest.pack_sequence_as(self._outputs_structure,\n",
      "\u001b[1;32m~\\.conda\\envs\\tcs\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[0;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1439\u001b[1;33m               run_metadata_ptr)\n\u001b[0m\u001b[0;32m   1440\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(X_train,Y_train, batch_size=128, epochs=10, validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.24566473988439305\n",
      "[[  0 323   0   0   0]\n",
      " [  0 425   0   0   0]\n",
      " [  0 300   0   0   0]\n",
      " [  0 280   0   0   0]\n",
      " [  0 402   0   0   0]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       323\n",
      "           1       0.25      1.00      0.39       425\n",
      "           2       0.00      0.00      0.00       300\n",
      "           3       0.00      0.00      0.00       280\n",
      "           4       0.00      0.00      0.00       402\n",
      "\n",
      "    accuracy                           0.25      1730\n",
      "   macro avg       0.05      0.20      0.08      1730\n",
      "weighted avg       0.06      0.25      0.10      1730\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "Y_test2=np.argmax(Y_test,axis=1)\n",
    "Y_pred=model.predict(X_test)\n",
    "#print(Y_pred)\n",
    "y_pred = np.argmax(Y_pred, axis=1)\n",
    "acc=accuracy_score(Y_test2, y_pred)\n",
    "print(acc)\n",
    "print(confusion_matrix(Y_test2,y_pred))\n",
    "print(classification_report(Y_test2,y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
